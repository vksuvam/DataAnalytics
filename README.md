# Data Analytics

<h3>Iris Classification</h3>

Iris classification is referred to as the "Hello World" of Machine Learning. Iris.csv file is iris flowers dataset that contains numeric attributes, and it is perfect to learn about supervised ML algorithms, mainly how to load and handle data. Also, since this is a small dataset, it can easily fit in memory without requiring special transformations capabilities or scaling.

![image](https://github.com/vksuvam/DataScience_LGM/assets/73656357/7c6b490d-82b0-4580-b403-3901ce23b3be)


<h3>Music Recommendation System</h3>

A music recommendation system is a machine learning system that predicts songs that users might like to hear based on their previous listening history. These systems are built using machine learning and artificial intelligence. The datasets used are songs.csv, songs_extra_info.csv, members.csv, train.csv & test.csv. 

![image](https://github.com/vksuvam/DataScience_LGM/assets/73656357/81e0d71d-fd2a-4a20-8837-7ebd2a43c9bd)


<h3>Image To Pencil Sketch Using Python</h3>

The first step is to read the image (i.e. test.jpg) in RGB format and then convert it into a grayscale image. This will turn an image into a classic B&W image. The next step is to invert the B&W image, aka the negative image. Inversion can be used to enhance details. Then we can finally create the pencil sketch by mixing the grayscale image with the inverted blurry image. This can be done by dividing the grayscale image by the inverted blurry image. Since images are just arrays, we can easily do this by using the divide function from the CV2 library in Python.

![Screenshot from 2023-09-30 20-41-56](https://github.com/vksuvam/DataScience_LGM/assets/73656357/b9b101f0-3b4c-4114-b1c8-0e4deb549e17)


<h3>Decision Tree Classifier</h3>

A decision tree classifier is a ML algorithm used for classification tasks. It is a supervised learning algorithm that can be used for both binary classification and multi-class classification.The decision tree classifier works by recursively partitioning the data into subsets based on the values of different input features. At each step, the algorithm selects the feature that provides the best split or separation of the data, with the goal of maximizing the separation between different classes. This process continues until a stopping criterion is met, such as a maximum tree depth or a minimum number of data points in a leaf node. Popular extensions of decision tree classifiers include Random Forests, Gradient Boosted Trees, and XGBoost, which aims to improve the performance and generalization of decision tree-based models.

![Screenshot from 2023-09-30 20-45-38](https://github.com/vksuvam/DataScience_LGM/assets/73656357/94846c28-2a48-45ae-a3c1-bfc0b1795510)

